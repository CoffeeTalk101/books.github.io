<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>机器学习中对不平衡数据的基线模型选择</title>
  <meta name="keywords" content="AI"/>
  <link href="../Styles/Style0001.css" type="text/css" rel="stylesheet"/>
</head>

<body>
<h1>机器学习中对不平衡数据的基线模型选择</h1>

<p class="date">2021-01-19</p>

<a class="home" href="https://xdcsy.github.io/">&lt; view all posts</a>

<p>对于数据集不平衡的机器学习问题，从不同的基线模型的预测结果计算出的评估指标可能是不同的。例如二分类中，某一类样本远比另一类多的情况，如果选择Accuracy作为评估指标，总是预测多数类的基线模型会比随机预测两类之一的模型得到高得多的分数。如果错误地选择了等概率随机预测的模型作为基线，就无法合理地衡量后续模型的表现。</p>

<p>*这篇笔记中的代码和实验出自<a href="https://machinelearningmastery.com/naive-classifiers-imbalanced-classification-metrics/">Machine Learning Mastery的一篇博客</a>，笔记里只对部分内容做了翻译和重新组织。有需要的可以进一步参考原文。</p>

<p>不同基线模型对Accuracy值的影响是很显然的，但其它一些指标，在使用不同的基线模型时分别会取到什么值则不是非常明显。我们可以通过使用scikit-learn库中的DummyClassifier类来进行试验。</p>

<p>使用的数据集是不平衡的，在1000000个样本中，99%为负样本，标记为0，1%为正样本，标记为1。</p>

<p>实验中使用的基线模型如下：</p>

<ul>
    <li>均匀随机猜测：以相等的概率预测0或1.</li>
    <li>先验随机猜测：根据数据集中样本分布的先验概率，按比例预测0或1.</li>
    <li>多数类：总是预测多数类的标签.</li>
    <li>少数类：总是预测少数类的标签.</li>
</ul>

<p>对于预测标签的评估指标，常用的有：</p>

<ul>
    <li>Accuracy.</li>
    <li>F1-Measure.</li>
    <li>ROC AUC，也叫AUROC(Area Under Receiver Operating Characteristics)</li>
    <li>Precision-Recall AUC，也叫AUPRC(Area Under Precision-Recall Curve)</li>
</ul>

<h2 class="sigil_not_in_toc">Accuracy</h2>

<!-- HTML generated using hilite.me --><div style="background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #0099FF; font-style: italic"># compare naive classifiers with classification accuracy metric</span>
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> mean
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> std
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.datasets</span> <span style="color: #006699; font-weight: bold">import</span> make_classification
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> cross_val_score
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> RepeatedStratifiedKFold
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.dummy</span> <span style="color: #006699; font-weight: bold">import</span> DummyClassifier
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">matplotlib</span> <span style="color: #006699; font-weight: bold">import</span> pyplot

<span style="color: #0099FF; font-style: italic"># evaluate a model</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">evaluate_model</span>(X, y, model):
	<span style="color: #0099FF; font-style: italic"># define evaluation procedure</span>
	cv <span style="color: #555555">=</span> RepeatedStratifiedKFold(n_splits<span style="color: #555555">=</span><span style="color: #FF6600">10</span>, n_repeats<span style="color: #555555">=</span><span style="color: #FF6600">3</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">1</span>)
	<span style="color: #0099FF; font-style: italic"># evaluate model</span>
	scores <span style="color: #555555">=</span> cross_val_score(model, X, y, scoring<span style="color: #555555">=</span><span style="color: #CC3300">'accuracy'</span>, cv<span style="color: #555555">=</span>cv, n_jobs<span style="color: #555555">=-</span><span style="color: #FF6600">1</span>)
	<span style="color: #006699; font-weight: bold">return</span> scores

<span style="color: #0099FF; font-style: italic"># define models to test</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">get_models</span>():
	models, names <span style="color: #555555">=</span> <span style="color: #336666">list</span>(), <span style="color: #336666">list</span>()
	<span style="color: #0099FF; font-style: italic"># Uniformly Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'uniform'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Uniform'</span>)
	<span style="color: #0099FF; font-style: italic"># Prior Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'stratified'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Stratified'</span>)
	<span style="color: #0099FF; font-style: italic"># Majority Class: Predict 0</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'most_frequent'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Majority'</span>)
	<span style="color: #0099FF; font-style: italic"># Minority Class: Predict 1</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'constant'</span>, constant<span style="color: #555555">=</span><span style="color: #FF6600">1</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Minority'</span>)
	<span style="color: #0099FF; font-style: italic"># Class Prior</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'prior'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Prior'</span>)
	<span style="color: #006699; font-weight: bold">return</span> models, names

<span style="color: #0099FF; font-style: italic"># define dataset</span>
X, y <span style="color: #555555">=</span> make_classification(n_samples<span style="color: #555555">=</span><span style="color: #FF6600">1000000</span>, n_features<span style="color: #555555">=</span><span style="color: #FF6600">2</span>, n_redundant<span style="color: #555555">=</span><span style="color: #FF6600">0</span>,
	n_clusters_per_class<span style="color: #555555">=</span><span style="color: #FF6600">1</span>, weights<span style="color: #555555">=</span>[<span style="color: #FF6600">0.99</span>], flip_y<span style="color: #555555">=</span><span style="color: #FF6600">0</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">4</span>)
<span style="color: #0099FF; font-style: italic"># define models</span>
models, names <span style="color: #555555">=</span> get_models()
results <span style="color: #555555">=</span> <span style="color: #336666">list</span>()
<span style="color: #0099FF; font-style: italic"># evaluate each model</span>
<span style="color: #006699; font-weight: bold">for</span> i <span style="color: #000000; font-weight: bold">in</span> <span style="color: #336666">range</span>(<span style="color: #336666">len</span>(models)):
	<span style="color: #0099FF; font-style: italic"># evaluate the model and store results</span>
	scores <span style="color: #555555">=</span> evaluate_model(X, y, models[i])
	results<span style="color: #555555">.</span>append(scores)
	<span style="color: #0099FF; font-style: italic"># summarize and store</span>
	<span style="color: #336666">print</span>(<span style="color: #CC3300">'&gt;%s %.3f (%.3f)'</span> <span style="color: #555555">%</span> (names[i], mean(scores), std(scores)))
<span style="color: #0099FF; font-style: italic"># plot the results</span>
pyplot<span style="color: #555555">.</span>boxplot(results, labels<span style="color: #555555">=</span>names, showmeans<span style="color: #555555">=</span><span style="color: #006699; font-weight: bold">True</span>)
pyplot<span style="color: #555555">.</span>show()
</pre>
</div>

<p>结果如下：</p>

<ul>
    <li>均匀随机猜测：0.5</li>
    <li>先验随机猜测：0.99</li>
    <li>多数类：0.99</li>
    <li>少数类：0.10</li>
</ul>

<p>可以看出，如果要使用Accuracy作为评价指标，那么基线模型应该选择预测多数类。</p>

<h2 class="sigil_not_in_toc">F1</h2>

<p>对少数类作预测(少数类是正样本)，并用F1值评估结果。</p>

<!-- HTML generated using hilite.me --><div style="background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #0099FF; font-style: italic"># compare naive classifiers with f1-measure</span>
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> mean
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> std
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.datasets</span> <span style="color: #006699; font-weight: bold">import</span> make_classification
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> cross_val_score
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> RepeatedStratifiedKFold
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.dummy</span> <span style="color: #006699; font-weight: bold">import</span> DummyClassifier
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">matplotlib</span> <span style="color: #006699; font-weight: bold">import</span> pyplot

<span style="color: #0099FF; font-style: italic"># evaluate a model</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">evaluate_model</span>(X, y, model):
	<span style="color: #0099FF; font-style: italic"># define evaluation procedure</span>
	cv <span style="color: #555555">=</span> RepeatedStratifiedKFold(n_splits<span style="color: #555555">=</span><span style="color: #FF6600">10</span>, n_repeats<span style="color: #555555">=</span><span style="color: #FF6600">3</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">1</span>)
	<span style="color: #0099FF; font-style: italic"># evaluate model</span>
	scores <span style="color: #555555">=</span> cross_val_score(model, X, y, scoring<span style="color: #555555">=</span><span style="color: #CC3300">'f1'</span>, cv<span style="color: #555555">=</span>cv, n_jobs<span style="color: #555555">=-</span><span style="color: #FF6600">1</span>)
	<span style="color: #006699; font-weight: bold">return</span> scores

<span style="color: #0099FF; font-style: italic"># define models to test</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">get_models</span>():
	models, names <span style="color: #555555">=</span> <span style="color: #336666">list</span>(), <span style="color: #336666">list</span>()
	<span style="color: #0099FF; font-style: italic"># Uniformly Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'uniform'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Uniform'</span>)
	<span style="color: #0099FF; font-style: italic"># Prior Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'stratified'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Stratified'</span>)
	<span style="color: #0099FF; font-style: italic"># Majority Class: Predict 0</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'most_frequent'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Majority'</span>)
	<span style="color: #0099FF; font-style: italic"># Minority Class: Predict 1</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'constant'</span>, constant<span style="color: #555555">=</span><span style="color: #FF6600">1</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Minority'</span>)
	<span style="color: #0099FF; font-style: italic"># Class Prior</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'prior'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Prior'</span>)
	<span style="color: #006699; font-weight: bold">return</span> models, names

<span style="color: #0099FF; font-style: italic"># define dataset</span>
X, y <span style="color: #555555">=</span> make_classification(n_samples<span style="color: #555555">=</span><span style="color: #FF6600">1000000</span>, n_features<span style="color: #555555">=</span><span style="color: #FF6600">2</span>, n_redundant<span style="color: #555555">=</span><span style="color: #FF6600">0</span>,
	n_clusters_per_class<span style="color: #555555">=</span><span style="color: #FF6600">1</span>, weights<span style="color: #555555">=</span>[<span style="color: #FF6600">0.99</span>], flip_y<span style="color: #555555">=</span><span style="color: #FF6600">0</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">4</span>)
<span style="color: #0099FF; font-style: italic"># define models</span>
models, names <span style="color: #555555">=</span> get_models()
results <span style="color: #555555">=</span> <span style="color: #336666">list</span>()
<span style="color: #0099FF; font-style: italic"># evaluate each model</span>
<span style="color: #006699; font-weight: bold">for</span> i <span style="color: #000000; font-weight: bold">in</span> <span style="color: #336666">range</span>(<span style="color: #336666">len</span>(models)):
	<span style="color: #0099FF; font-style: italic"># evaluate the model and store results</span>
	scores <span style="color: #555555">=</span> evaluate_model(X, y, models[i])
	results<span style="color: #555555">.</span>append(scores)
	<span style="color: #0099FF; font-style: italic"># summarize and store</span>
	<span style="color: #336666">print</span>(<span style="color: #CC3300">'&gt;%s %.3f (%.3f)'</span> <span style="color: #555555">%</span> (names[i], mean(scores), std(scores)))
<span style="color: #0099FF; font-style: italic"># plot the results</span>
pyplot<span style="color: #555555">.</span>boxplot(results, labels<span style="color: #555555">=</span>names, showmeans<span style="color: #555555">=</span><span style="color: #006699; font-weight: bold">True</span>)
pyplot<span style="color: #555555">.</span>show()
</pre>
</div>

<p>结果如下：</p>

<ul>
    <li>均匀随机猜测：0.02</li>
    <li>先验随机猜测：0.01</li>
    <li>多数类（负类）：0</li>
    <li>少数类（正类）：0.02</li>
</ul>

<p>可以看出，如果使用F1作为评价指标，且正样本为少数类，应该使用预测少数类为基线模型（虽然均匀随机猜测在实验中得到的F1是一样的，但是它具有随机性，因此还是预测少数类更好）。</p>

<p>调整一下，将正样本作为多数类(交换正负样本比)，则有：</p>

<ul>
    <li>均匀随机猜测：0.665</li>
    <li>先验随机猜测：0.99</li>
    <li>多数类（正类）：0.995</li>
    <li>少数类（负类）：0</li>
</ul>

<p>再调整正负样本比为1:1，则有：</p>

<ul>
    <li>均匀随机猜测：0.5</li>
    <li>先验随机猜测：0.5</li>
    <li>预测正类：0.667</li>
    <li>预测负类：0</li>
</ul>

<p>因此可以总结出，在以F1为评估指标时，基线模型的选择其实和正负样本的比例无关，而应该选择总是预测正样本。</p>

<h2 class="sigil_not_in_toc">ROC AUC</h2>

<!-- HTML generated using hilite.me --><div style="background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #0099FF; font-style: italic"># compare naive classifiers with roc auc</span>
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> mean
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> std
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.datasets</span> <span style="color: #006699; font-weight: bold">import</span> make_classification
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> cross_val_score
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> RepeatedStratifiedKFold
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.dummy</span> <span style="color: #006699; font-weight: bold">import</span> DummyClassifier
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">matplotlib</span> <span style="color: #006699; font-weight: bold">import</span> pyplot

<span style="color: #0099FF; font-style: italic"># evaluate a model</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">evaluate_model</span>(X, y, model):
	<span style="color: #0099FF; font-style: italic"># define evaluation procedure</span>
	cv <span style="color: #555555">=</span> RepeatedStratifiedKFold(n_splits<span style="color: #555555">=</span><span style="color: #FF6600">10</span>, n_repeats<span style="color: #555555">=</span><span style="color: #FF6600">3</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">1</span>)
	<span style="color: #0099FF; font-style: italic"># evaluate model</span>
	scores <span style="color: #555555">=</span> cross_val_score(model, X, y, scoring<span style="color: #555555">=</span><span style="color: #CC3300">'roc_auc'</span>, cv<span style="color: #555555">=</span>cv, n_jobs<span style="color: #555555">=-</span><span style="color: #FF6600">1</span>)
	<span style="color: #006699; font-weight: bold">return</span> scores

<span style="color: #0099FF; font-style: italic"># define models to test</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">get_models</span>():
	models, names <span style="color: #555555">=</span> <span style="color: #336666">list</span>(), <span style="color: #336666">list</span>()
	<span style="color: #0099FF; font-style: italic"># Uniformly Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'uniform'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Uniform'</span>)
	<span style="color: #0099FF; font-style: italic"># Prior Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'stratified'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Stratified'</span>)
	<span style="color: #0099FF; font-style: italic"># Majority Class: Predict 0</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'most_frequent'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Majority'</span>)
	<span style="color: #0099FF; font-style: italic"># Minority Class: Predict 1</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'constant'</span>, constant<span style="color: #555555">=</span><span style="color: #FF6600">1</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Minority'</span>)
	<span style="color: #0099FF; font-style: italic"># Class Prior</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'prior'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Prior'</span>)
	<span style="color: #006699; font-weight: bold">return</span> models, names

<span style="color: #0099FF; font-style: italic"># define dataset</span>
X, y <span style="color: #555555">=</span> make_classification(n_samples<span style="color: #555555">=</span><span style="color: #FF6600">1000000</span>, n_features<span style="color: #555555">=</span><span style="color: #FF6600">2</span>, n_redundant<span style="color: #555555">=</span><span style="color: #FF6600">0</span>,
	n_clusters_per_class<span style="color: #555555">=</span><span style="color: #FF6600">1</span>, weights<span style="color: #555555">=</span>[<span style="color: #FF6600">0.99</span>], flip_y<span style="color: #555555">=</span><span style="color: #FF6600">0</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">4</span>)
<span style="color: #0099FF; font-style: italic"># define models</span>
models, names <span style="color: #555555">=</span> get_models()
results <span style="color: #555555">=</span> <span style="color: #336666">list</span>()
<span style="color: #0099FF; font-style: italic"># evaluate each model</span>
<span style="color: #006699; font-weight: bold">for</span> i <span style="color: #000000; font-weight: bold">in</span> <span style="color: #336666">range</span>(<span style="color: #336666">len</span>(models)):
	<span style="color: #0099FF; font-style: italic"># evaluate the model and store results</span>
	scores <span style="color: #555555">=</span> evaluate_model(X, y, models[i])
	results<span style="color: #555555">.</span>append(scores)
	<span style="color: #0099FF; font-style: italic"># summarize and store</span>
	<span style="color: #336666">print</span>(<span style="color: #CC3300">'&gt;%s %.3f (%.3f)'</span> <span style="color: #555555">%</span> (names[i], mean(scores), std(scores)))
<span style="color: #0099FF; font-style: italic"># plot the results</span>
pyplot<span style="color: #555555">.</span>boxplot(results, labels<span style="color: #555555">=</span>names, showmeans<span style="color: #555555">=</span><span style="color: #006699; font-weight: bold">True</span>)
pyplot<span style="color: #555555">.</span>show()
</pre>
</div>

<p>结果如下：</p>

<ul>
    <li>均匀随机猜测：0.5</li>
    <li>先验随机猜测：0.5</li>
    <li>多数类：0.5</li>
    <li>少数类：0.5</li>
</ul>

<p>调整正负样本比，结果并不改变，始终为0.5。这里我们可以看出，AUROC这个指标有着和正负样本比无关的特性。这使得它成为在正负样本比可能产生波动，或者当模型在不同场景间移植的时候，评估模型效果的一个很稳定的指标。</p>

<p>简单起见，使用AUROC的时候，基线模型随意预测结果为一个固定类即可。</p>

<h2 class="sigil_not_in_toc">Precision-Recall AUC</h2>

<!-- HTML generated using hilite.me --><div style="background: #f0f3f3; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #0099FF; font-style: italic"># compare naive classifiers with precision-recall auc metric</span>
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> mean
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">numpy</span> <span style="color: #006699; font-weight: bold">import</span> std
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.datasets</span> <span style="color: #006699; font-weight: bold">import</span> make_classification
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> cross_val_score
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.model_selection</span> <span style="color: #006699; font-weight: bold">import</span> RepeatedStratifiedKFold
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.dummy</span> <span style="color: #006699; font-weight: bold">import</span> DummyClassifier
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.metrics</span> <span style="color: #006699; font-weight: bold">import</span> precision_recall_curve
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.metrics</span> <span style="color: #006699; font-weight: bold">import</span> auc
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">sklearn.metrics</span> <span style="color: #006699; font-weight: bold">import</span> make_scorer
<span style="color: #006699; font-weight: bold">from</span> <span style="color: #00CCFF; font-weight: bold">matplotlib</span> <span style="color: #006699; font-weight: bold">import</span> pyplot

<span style="color: #0099FF; font-style: italic"># calculate precision-recall area under curve</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">pr_auc</span>(y_true, probas_pred):
	<span style="color: #0099FF; font-style: italic"># calculate precision-recall curve</span>
	p, r, _ <span style="color: #555555">=</span> precision_recall_curve(y_true, probas_pred)
	<span style="color: #0099FF; font-style: italic"># calculate area under curve</span>
	<span style="color: #006699; font-weight: bold">return</span> auc(r, p)

<span style="color: #0099FF; font-style: italic"># evaluate a model</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">evaluate_model</span>(X, y, model):
	<span style="color: #0099FF; font-style: italic"># define evaluation procedure</span>
	cv <span style="color: #555555">=</span> RepeatedStratifiedKFold(n_splits<span style="color: #555555">=</span><span style="color: #FF6600">10</span>, n_repeats<span style="color: #555555">=</span><span style="color: #FF6600">3</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">1</span>)
	<span style="color: #0099FF; font-style: italic"># define the model evaluation the metric</span>
	metric <span style="color: #555555">=</span> make_scorer(pr_auc, needs_proba<span style="color: #555555">=</span><span style="color: #006699; font-weight: bold">True</span>)
	<span style="color: #0099FF; font-style: italic"># evaluate model</span>
	scores <span style="color: #555555">=</span> cross_val_score(model, X, y, scoring<span style="color: #555555">=</span>metric, cv<span style="color: #555555">=</span>cv, n_jobs<span style="color: #555555">=-</span><span style="color: #FF6600">1</span>)
	<span style="color: #006699; font-weight: bold">return</span> scores

<span style="color: #0099FF; font-style: italic"># define models to test</span>
<span style="color: #006699; font-weight: bold">def</span> <span style="color: #CC00FF">get_models</span>():
	models, names <span style="color: #555555">=</span> <span style="color: #336666">list</span>(), <span style="color: #336666">list</span>()
	<span style="color: #0099FF; font-style: italic"># Uniformly Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'uniform'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Uniform'</span>)
	<span style="color: #0099FF; font-style: italic"># Prior Random Guess</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'stratified'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Stratified'</span>)
	<span style="color: #0099FF; font-style: italic"># Majority Class: Predict 0</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'most_frequent'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Majority'</span>)
	<span style="color: #0099FF; font-style: italic"># Minority Class: Predict 1</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'constant'</span>, constant<span style="color: #555555">=</span><span style="color: #FF6600">1</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Minority'</span>)
	<span style="color: #0099FF; font-style: italic"># Class Prior</span>
	models<span style="color: #555555">.</span>append(DummyClassifier(strategy<span style="color: #555555">=</span><span style="color: #CC3300">'prior'</span>))
	names<span style="color: #555555">.</span>append(<span style="color: #CC3300">'Prior'</span>)
	<span style="color: #006699; font-weight: bold">return</span> models, names

<span style="color: #0099FF; font-style: italic"># define dataset</span>
X, y <span style="color: #555555">=</span> make_classification(n_samples<span style="color: #555555">=</span><span style="color: #FF6600">1000000</span>, n_features<span style="color: #555555">=</span><span style="color: #FF6600">2</span>, n_redundant<span style="color: #555555">=</span><span style="color: #FF6600">0</span>,
	n_clusters_per_class<span style="color: #555555">=</span><span style="color: #FF6600">1</span>, weights<span style="color: #555555">=</span>[<span style="color: #FF6600">0.99</span>], flip_y<span style="color: #555555">=</span><span style="color: #FF6600">0</span>, random_state<span style="color: #555555">=</span><span style="color: #FF6600">4</span>)
<span style="color: #0099FF; font-style: italic"># define models</span>
models, names <span style="color: #555555">=</span> get_models()
results <span style="color: #555555">=</span> <span style="color: #336666">list</span>()
<span style="color: #0099FF; font-style: italic"># evaluate each model</span>
<span style="color: #006699; font-weight: bold">for</span> i <span style="color: #000000; font-weight: bold">in</span> <span style="color: #336666">range</span>(<span style="color: #336666">len</span>(models)):
	<span style="color: #0099FF; font-style: italic"># evaluate the model and store results</span>
	scores <span style="color: #555555">=</span> evaluate_model(X, y, models[i])
	results<span style="color: #555555">.</span>append(scores)
	<span style="color: #0099FF; font-style: italic"># summarize and store</span>
	<span style="color: #336666">print</span>(<span style="color: #CC3300">'&gt;%s %.3f (%.3f)'</span> <span style="color: #555555">%</span> (names[i], mean(scores), std(scores)))
<span style="color: #0099FF; font-style: italic"># plot the results</span>
pyplot<span style="color: #555555">.</span>boxplot(results, labels<span style="color: #555555">=</span>names, showmeans<span style="color: #555555">=</span><span style="color: #006699; font-weight: bold">True</span>)
pyplot<span style="color: #555555">.</span>show()
</pre>
</div>

<p>结果如下：</p>

<ul>
    <li>均匀随机猜测：0.505</li>
    <li>先验随机猜测：0.015</li>
    <li>多数类：0.505</li>
    <li>少数类：0.505</li>
</ul>

<p>将正样本作为多数类(交换正负样本比)，则有：</p>

<ul>
    <li>均匀随机猜测：0.995</li>
    <li>先验随机猜测：0.995</li>
    <li>多数类：0.995</li>
    <li>少数类：0.995</li>
</ul>

<p>正负样本比相同时，结果为：</p>

<ul>
    <li>均匀随机猜测：0.75</li>
    <li>先验随机猜测：0.625</li>
    <li>多数类：0.75</li>
    <li>少数类：0.75</li>
</ul>

<p>可以看到，使用AURPC的时候，基线模型也是预测为一个固定类即可。</p>

<p>不过需要注意的时，AURPC的基线值和正负样本比是有关的，因此在不同场景间不能直接进行比较。另外，先验随即猜测的基线值实际上是偏低的：在正样本数量很少时，先验随机猜测的评估值(上面的实验中为0.015)，比起其它基线(0.505)低了很多。</p>

<p>再结合对其它的几个评估指标的实验，可以发现在对二分类问题的评估中，实际上先验随机猜测这个基线并没有什么作用：它不是任何评估指标的唯一最好基线，而且评估结果的方差很大，稳定性差。建议不要使用。</p>
<hr/>
<p class="footer">This blog is written in  EPUB.
The original file is available for <a href="https://github.com/XDcsy/XDcsy.github.io/raw/main/blog.epub">download</a>.</p>
<p class="footer">Feel free to comment by <a href="https://github.com/XDcsy/XDcsy.github.io/issues/new">raising an issue <img alt="GitHub-Mark-32px" src="../Images/GitHub-Mark-32px.png" class="github"/></a>.</p>
</body>
</html>